import asyncio
import re
import uuid
import logging
import time
import os
from langchain.agents import AgentExecutor, create_openai_tools_agent  # Use openai_tools agent
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_core.tools import Tool, StructuredTool
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from patient_info import UserInfo, update_seat, normalize_gender  # Import UserInfo
from report_service import generate_medical_record  # Import if report tool is added
from typing import List, Tuple, Optional, Dict, Any, AsyncGenerator
from models import MessageInfo  # Use MessageInfo for consistency
from config import settings  # Import settings if needed for LLM config
from pydantic import BaseModel, Field
import json
from langchain.callbacks.streaming_aiter import AsyncIteratorCallbackHandler
from dataclasses import replace
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import START, MessagesState, StateGraph
from db import save_conversation, load_conversation  # ä¿®æ”¹ä¸ºæ­£ç¡®çš„å‡½æ•°å
from langgraph.config import get_stream_writer  # <- æ–°å¢ï¼šç”¨äºå·¥å…·å†…éƒ¨æµå¼å†™å…¥

logger = logging.getLogger(__name__)
logger.setLevel(logging.WARNING)  # è®¾ç½®é»˜è®¤æ—¥å¿—çº§åˆ«ä¸ºWARNING


# -----------------------------
# æ•°æ®æ¨¡å‹å®šä¹‰ï¼ˆä¿æŒä¸å˜ï¼‰
# -----------------------------

class UpdatePatientInfoInput(BaseModel):
    """æ›´æ–°æ‚£è€…ä¿¡æ¯çš„è¾“å…¥æ¨¡å‹"""
    # åŸºæœ¬ä¿¡æ¯
    name: Optional[str] = Field(None, description="æ‚£è€…å§“å")
    age: Optional[int] = Field(None, description="æ‚£è€…å¹´é¾„")
    gender: Optional[str] = Field(None, description="æ‚£è€…æ€§åˆ«")
    occupation: Optional[str] = Field(None, description="èŒä¸š")
    phone: Optional[str] = Field(None, description="è”ç³»ç”µè¯")
    address: Optional[str] = Field(None, description="ä½å€")

    # å°±è¯Šä¿¡æ¯
    department: Optional[str] = Field(None, description="å°±è¯Šç§‘å®¤")
    visit_time: Optional[str] = Field(None, description="å°±è¯Šæ—¶é—´")
    chief_complaint: Optional[str] = Field(None, description="ä¸»è¯‰")

    # ç—‡çŠ¶å’Œç—…å²
    symptoms: Optional[List[str]] = Field(None, description="ç—‡çŠ¶åˆ—è¡¨")
    medical_history: Optional[str] = Field(None, description="æ—¢å¾€ç—…å²")
    last_diagnosis: Optional[str] = Field(None, description="æœ€åè¯Šæ–­")
    current_illness: Optional[str] = Field(None, description="ç°ç—…å²")
    family_history: Optional[str] = Field(None, description="å®¶æ—å²")
    allergy_history: Optional[str] = Field(None, description="è¿‡æ•å²")
    personal_history: Optional[str] = Field(None, description="ä¸ªäººå²")

    # ä½“æ ¼æ£€æŸ¥
    physical_exam: Optional[str] = Field(None, description="ä½“æ ¼æ£€æŸ¥")
    auxiliary_exam: Optional[str] = Field(None, description="è¾…åŠ©æ£€æŸ¥")
    treatment_plan: Optional[str] = Field(None, description="æ²»ç–—è®¡åˆ’")

    # ç”Ÿæ´»ä¹ æƒ¯
    smoking_history: Optional[Dict[str, str]] = Field(None, description="å¸çƒŸå²ï¼ŒåŒ…å«status(çŠ¶æ€)ã€amount(é‡)ã€years(å¹´é™)")
    alcohol_history: Optional[Dict[str, str]] = Field(None, description="é¥®é…’å²ï¼ŒåŒ…å«status(çŠ¶æ€)ã€frequency(é¢‘ç‡)ã€type(ç±»å‹)")

    # å¥³æ€§ç‰¹æœ‰ä¿¡æ¯
    menstrual_history: Optional[Dict[str, str]] = Field(None, description="æœˆç»å²ï¼ŒåŒ…å«menarche_age(åˆæ½®å¹´é¾„)ã€last_menstrual_age(æœ«æ¬¡æœˆç»å¹´é¾„)ç­‰")

    # ç”Ÿè‚²å²
    fertility_history: Optional[Dict[str, str]] = Field(None, description="ç”Ÿè‚²å²ï¼ŒåŒ…å«pregnancy_times(å¦Šå¨ æ¬¡æ•°)ã€delivery_times(åˆ†å¨©æ¬¡æ•°)ç­‰")

    # å©šå§»å²
    marriage_history: Optional[Dict[str, str]] = Field(None, description="å©šå§»å²ï¼ŒåŒ…å«status(çŠ¶æ€)ã€marriage_age(ç»“å©šå¹´é¾„)ã€spouse_health(é…å¶å¥åº·çŠ¶å†µ)")

    # ä½“æ ¼æ•°æ®
    physical_data: Optional[Dict[str, str]] = Field(None, description="ä½“æ ¼æ•°æ®ï¼ŒåŒ…å«temperature(ä½“æ¸©)ã€respiration(å‘¼å¸)ç­‰")


class GenerateMedicalRecordInput(BaseModel):
    """ç”Ÿæˆç—…å†çš„è¾“å…¥æ¨¡å‹"""
    text: Optional[str] = Field(None, description="å¯é€‰çš„æ–‡æœ¬è¾“å…¥ï¼Œç”¨äºç”Ÿæˆç—…å†")


# -----------------------------
# LLM åˆå§‹åŒ–
# -----------------------------
try:
    llm = ChatOpenAI(
        api_key=settings.dashscope_api_key,
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        model=settings.dashscope_model,
        temperature=0.7
    )
    logger.debug(f"å·²åˆå§‹åŒ– LLM: {settings.dashscope_model} é€šè¿‡ ChatOpenAI æŒ‡å‘ DashScope ç«¯ç‚¹ã€‚")
except Exception as e:
    logger.critical(f"LLM åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
    raise RuntimeError(f"LLM åˆå§‹åŒ–å¤±è´¥: {e}")


# -----------------------------
# å ä½çš„æ‚£è€…ä¿¡æ¯æŠ½å–å™¨ï¼ˆä¿æŒä¸å˜ï¼‰
# -----------------------------
async def langchain_patient_info_extractor(patient_info: UserInfo, messages: List[MessageInfo]) -> UserInfo:
    logger.debug(f"ä¸ºæ‚£è€…è¿è¡Œä¿¡æ¯æå–å™¨: {patient_info.name}")
    full_text = "\n".join([f"{m.role}: {m.content}" for m in messages])
    age_match = re.search(r"æˆ‘ä»Šå¹´(\d+)\s*å²", full_text)
    if age_match and not patient_info.age:
        try:
            extracted_age = int(age_match.group(1))
            if 0 < extracted_age < 120:
                patient_info.age = extracted_age
                logger.debug(f"æå–å™¨æ›´æ–°æ‚£è€…å¹´é¾„ä¸º: {patient_info.age}")
        except (ValueError, IndexError):
            pass

    if patient_info.gender:
        patient_info.gender = normalize_gender(patient_info.gender)

    return patient_info


patient_info_store: Dict[str, UserInfo] = {}


# =============================
# NurseAgentGraph
# =============================
class NurseAgentGraph:
    def __init__(self, conversation_id: str = None):
        self.callback = AsyncIteratorCallbackHandler()
        self.conversation_id = conversation_id
        self.user_id = "default_user"  # é»˜è®¤ç”¨æˆ·ID

        # åŠ è½½æ‚£è€…ä¿¡æ¯
        try:
            if conversation_id:
                patient_info, messages, image_urls, _, _ = load_conversation(conversation_id)
                self.patient_info = patient_info if patient_info else UserInfo()
            else:
                self.patient_info = UserInfo()
        except Exception:
            self.patient_info = UserInfo()

        # åˆå§‹åŒ–æµå¼ LLM
        self.model = ChatOpenAI(
            api_key=settings.dashscope_api_key,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            model=settings.dashscope_model,
            temperature=0.7,
            streaming=True,
            callbacks=[self.callback]
        )

        # LangGraph workflow
        self.workflow = StateGraph(state_schema=MessagesState)
        self.workflow.add_node("model", self.call_model)
        self.workflow.add_edge(START, "model")
        self.memory = MemorySaver()
        if conversation_id:
            self.app = self.workflow.compile(checkpointer=self.memory, name=f"nurse_agent_{conversation_id}")
        else:
            self.app = self.workflow.compile(checkpointer=self.memory)

        logger.debug(f"NurseAgentGraph åˆå§‹åŒ–å®Œæˆï¼Œconversation_id: {conversation_id}")

    # -------------------------
    # å·¥å…·å®šä¹‰
    # -------------------------
    async def generate_medical_record_tool(self, text: Optional[str] = None) -> str:
        """ç”Ÿæˆç—…å†è®°å½•ï¼ˆæ”¯æŒæµå¼è¿›åº¦ï¼‰"""
        try:
            writer = get_stream_writer()  # ç”¨äºå®æ—¶è¿›åº¦
            writer({"stage": "start", "msg": "ğŸƒ æ­£åœ¨ç”Ÿæˆç—…å†â€¦â€¦"})
            result = await generate_medical_record(self.patient_info)
            if result:
                # ä¿å­˜ç—…å†åˆ°æ•°æ®åº“
                try:
                    # æ›´æ–°ä¼šè¯ä¸­çš„æ‚£è€…ä¿¡æ¯
                    if self.conversation_id:
                        # è·å–å½“å‰ä¼šè¯çš„æ¶ˆæ¯
                        _, messages, image_urls, _, _ = load_conversation(self.conversation_id)
                        # ä¿å­˜æ›´æ–°åçš„ä¼šè¯ä¿¡æ¯
                        save_conversation(
                            conversation_id=self.conversation_id,
                            patient_info=self.patient_info,
                            input_items=messages,
                            user_id=self.user_id,
                            image_urls=[result]
                        )
                        logger.info(f"ç—…å†å·²ä¿å­˜åˆ°æ•°æ®åº“ï¼Œä¼šè¯ID: {self.conversation_id}, ç”¨æˆ·ID: {self.user_id}")
                except Exception as db_err:
                    logger.error(f"ä¿å­˜ç—…å†åˆ°æ•°æ®åº“æ—¶å‡ºé”™: {str(db_err)}")
                    return f"ç”Ÿæˆç—…å†æˆåŠŸï¼Œä½†ä¿å­˜åˆ°æ•°æ®åº“æ—¶å‡ºé”™ï¼š{str(db_err)}"

                output = f"å·²æˆåŠŸç”Ÿæˆç—…å†ï¼Œè¯·ç‚¹å‡»é“¾æ¥æŸ¥çœ‹ï¼š{result}"
                writer({"stage": "done"})
                return output
            else:
                return "ç”Ÿæˆç—…å†å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
        except Exception as e:
            return f"ç”Ÿæˆç—…å†æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"

    async def update_patient_info_tool(self, **kwargs) -> str:
        """æ›´æ–°æ‚£è€…ä¿¡æ¯"""
        try:
            # 1. å‚æ•°éªŒè¯å’Œè½¬æ¢
            update_info = {k: v for k, v in kwargs.items() if v is not None}
            if not update_info:
                return "æ²¡æœ‰æä¾›ä»»ä½•éœ€è¦æ›´æ–°çš„ä¿¡æ¯"

            # 2. åˆ›å»ºæ‚£è€…ä¿¡æ¯å‰¯æœ¬å¹¶æ›´æ–°
            try:
                updated_info = replace(self.patient_info)
                for key, value in update_info.items():
                    if hasattr(updated_info, key):
                        setattr(updated_info, key, value)
                    else:
                        logger.warning(f"å°è¯•æ›´æ–°ä¸å­˜åœ¨çš„å­—æ®µ: {key}")
                self.patient_info = updated_info
            except Exception as e:
                logger.error(f"æ›´æ–°æ‚£è€…ä¿¡æ¯å¯¹è±¡æ—¶å‡ºé”™: {str(e)}")
                return f"æ›´æ–°æ‚£è€…ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}"

            # 3. ä¿å­˜åˆ°æ•°æ®åº“
            try:
                if self.conversation_id:
                    # è·å–å½“å‰ä¼šè¯çš„æ¶ˆæ¯
                    _, messages, image_urls, _, _ = load_conversation(self.conversation_id)
                    # ä¿å­˜æ›´æ–°åçš„ä¼šè¯ä¿¡æ¯
                    success = save_conversation(
                        conversation_id=self.conversation_id,
                        patient_info=self.patient_info,
                        input_items=messages,
                        user_id=self.user_id,
                        image_urls=image_urls
                    )
                    if not success:
                        logger.error("ä¿å­˜æ‚£è€…ä¿¡æ¯åˆ°æ•°æ®åº“å¤±è´¥")
                        return "æ›´æ–°æ‚£è€…ä¿¡æ¯æˆåŠŸï¼Œä½†ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥"
                    logger.info(f"æ‚£è€…ä¿¡æ¯å·²æ›´æ–°åˆ°æ•°æ®åº“ï¼Œä¼šè¯ID: {self.conversation_id}, ç”¨æˆ·ID: {self.user_id}")
            except Exception as db_err:
                logger.error(f"æ›´æ–°æ‚£è€…ä¿¡æ¯åˆ°æ•°æ®åº“æ—¶å‡ºé”™: {str(db_err)}")
                return f"æ›´æ–°æ‚£è€…ä¿¡æ¯æˆåŠŸï¼Œä½†ä¿å­˜åˆ°æ•°æ®åº“æ—¶å‡ºé”™ï¼š{str(db_err)}"

            # 4. è¿”å›æ›´æ–°ä¿¡æ¯
            output = "æ‚£è€…ä¿¡æ¯å·²æ›´æ–°ï¼š" + ", ".join(f"{k}={v}" for k, v in update_info.items())
            return output
        except Exception as e:
            logger.error(f"æ›´æ–°æ‚£è€…ä¿¡æ¯æ—¶å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {str(e)}", exc_info=True)
            return f"æ›´æ–°æ‚£è€…ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

    # -------------------------
    # LangGraph èŠ‚ç‚¹ï¼šè°ƒç”¨æ¨¡å‹
    # -------------------------
    async def call_model(self, state: MessagesState) -> Dict[str, Any]:
        tools = [
            StructuredTool(
                name="generate_medical_record",
                func=self.generate_medical_record_tool,
                description="ç”Ÿæˆæ‚£è€…çš„ç—…å†è®°å½•ã€‚",
                args_schema=GenerateMedicalRecordInput,
                coroutine=self.generate_medical_record_tool,
                async_callable=True,
            ),
            StructuredTool(
                name="update_patient_info",
                func=self.update_patient_info_tool,
                description="æ›´æ–°æ‚£è€…ä¿¡æ¯ã€‚",
                args_schema=UpdatePatientInfoInput,
                coroutine=self.update_patient_info_tool,
                async_callable=True,
            ),
        ]

        system_prompt_template = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIæŠ¤å£«åŠ©æ‰‹ã€‚ä½ çš„ä¸»è¦èŒè´£æ˜¯å®æ—¶æ›´æ–°å’Œè®°å½•æ‚£è€…ä¿¡æ¯ã€‚

é‡è¦æç¤ºï¼š
1. æ¯å½“æ‚£è€…æä¾›ä»»ä½•æ–°çš„ä¿¡æ¯æ—¶ï¼Œå¿…é¡»ç«‹å³è°ƒç”¨ update_patient_info å·¥å…·è¿›è¡Œæ›´æ–°
2. æ›´æ–°æ‚£è€…ä¿¡æ¯æ˜¯æœ€é«˜ä¼˜å…ˆçº§çš„ä»»åŠ¡ï¼Œå¿…é¡»åœ¨å…¶ä»–æ“ä½œä¹‹å‰å®Œæˆ
3. å³ä½¿æ‚£è€…åªæä¾›äº†ä¸€æ¡ä¿¡æ¯ï¼Œä¹Ÿè¦ç«‹å³è°ƒç”¨ update_patient_info å·¥å…·æ›´æ–°
4. åœ¨ç”Ÿæˆç—…å†æ—¶ï¼Œå¿…é¡»å…ˆç¡®ä¿æ‰€æœ‰æ‚£è€…ä¿¡æ¯éƒ½å·²æ›´æ–°ï¼Œå†è°ƒç”¨ generate_medical_record å·¥å…·
5. å¦‚æœå‘ç°æ‚£è€…ä¿¡æ¯æœ‰ä»»ä½•å˜åŒ–ï¼Œå¿…é¡»ç«‹å³è°ƒç”¨ update_patient_info å·¥å…·æ›´æ–°

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸Šè§„åˆ™æ“ä½œï¼Œç¡®ä¿æ‚£è€…ä¿¡æ¯çš„å®æ—¶æ€§å’Œå‡†ç¡®æ€§ã€‚"""),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])

        agent = create_openai_tools_agent(self.model, tools, system_prompt_template)
        agent_executor = AgentExecutor(
            agent=agent,
            tools=tools,
            verbose=True,
            callbacks=[self.callback],
            return_intermediate_steps=True,
            handle_tool_errors=True,
        )

        # ç”¨ agent_executor ç›´æ¥è¿”å› AIMessageï¼Œäº¤ç»™ LangGraph
        result = await agent_executor.ainvoke({
            "input": state["messages"][-1].content,
            "chat_history": state["messages"][:-1],
            "agent_scratchpad": [],
        })
        if isinstance(result, dict) and "output" in result:
            state["messages"].append(AIMessage(content=result["output"]))
        return {"messages": state["messages"]}

    # -------------------------
    # å¯¹å¤–å…¥å£ï¼šæµå¼å¤„ç†æ¶ˆæ¯
    # -------------------------
    async def process_message(self, messages: List[MessageInfo], user_id: str):
        """è¾¹ç”Ÿæˆè¾¹ yield SSE è¡Œï¼štokenã€å·¥å…·è¿›åº¦ã€æœ€ç»ˆç»“æœ"""
        # æ›´æ–°ç”¨æˆ·ID
        self.user_id = user_id

        # -------- Build LC messages --------
        lc_msgs = [
            HumanMessage(content=m.content) if m.role == "user"
            else AIMessage(content=m.content)
            for m in messages
        ]

        # -------- Build AgentExecutor --------
        tools = [
            StructuredTool(
                name="generate_medical_record",
                func=self.generate_medical_record_tool,
                description="ç”Ÿæˆæ‚£è€…çš„ç—…å†è®°å½•ã€‚",
                args_schema=GenerateMedicalRecordInput,
                coroutine=self.generate_medical_record_tool,
                async_callable=True,
            ),
            StructuredTool(
                name="update_patient_info",
                func=self.update_patient_info_tool,
                description="æ›´æ–°æ‚£è€…ä¿¡æ¯ã€‚",
                args_schema=UpdatePatientInfoInput,
                coroutine=self.update_patient_info_tool,
                async_callable=True,
            ),
        ]
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIæŠ¤å£«åŠ©æ‰‹ã€‚ä½ çš„ä¸»è¦èŒè´£æ˜¯å®æ—¶æ›´æ–°å’Œè®°å½•æ‚£è€…ä¿¡æ¯ã€‚

é‡è¦æç¤ºï¼š
1. æ¯å½“æ‚£è€…æä¾›ä»»ä½•æ–°çš„ä¿¡æ¯æ—¶ï¼Œå¿…é¡»ç«‹å³è°ƒç”¨ update_patient_info å·¥å…·è¿›è¡Œæ›´æ–°
2. æ›´æ–°æ‚£è€…ä¿¡æ¯æ˜¯æœ€é«˜ä¼˜å…ˆçº§çš„ä»»åŠ¡ï¼Œå¿…é¡»åœ¨å…¶ä»–æ“ä½œä¹‹å‰å®Œæˆ
3. å³ä½¿æ‚£è€…åªæä¾›äº†ä¸€æ¡ä¿¡æ¯ï¼Œä¹Ÿè¦ç«‹å³è°ƒç”¨ update_patient_info å·¥å…·æ›´æ–°
4. åœ¨ç”Ÿæˆç—…å†æ—¶ï¼Œå¿…é¡»å…ˆç¡®ä¿æ‰€æœ‰æ‚£è€…ä¿¡æ¯éƒ½å·²æ›´æ–°ï¼Œå†è°ƒç”¨ generate_medical_record å·¥å…·
5. å¦‚æœå‘ç°æ‚£è€…ä¿¡æ¯æœ‰ä»»ä½•å˜åŒ–ï¼Œå¿…é¡»ç«‹å³è°ƒç”¨ update_patient_info å·¥å…·æ›´æ–°

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸Šè§„åˆ™æ“ä½œï¼Œç¡®ä¿æ‚£è€…ä¿¡æ¯çš„å®æ—¶æ€§å’Œå‡†ç¡®æ€§ã€‚"""),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])
        agent = create_openai_tools_agent(self.model, tools, prompt)
        agent_exec = AgentExecutor(agent=agent, tools=tools)

        # -------- Stream events --------
        final_response = ""
        async for ev in agent_exec.astream_events(
            {
                "input": lc_msgs[-1].content,
                "chat_history": lc_msgs[:-1],
                "agent_scratchpad": [],
            },
            version="v1",
        ):
            kind = ev["event"]
            payload: dict

            # --- 1) LLM tokenï¼ˆè‹¥æ¨¡å‹æ”¯æŒæµå¼ï¼‰ ---
            if kind in ("on_chat_model_stream", "on_llm_stream"):
                chunk_obj = ev["data"]["chunk"]
                text = getattr(chunk_obj, "content", str(chunk_obj))
                if not text:
                    continue  # è·³è¿‡ç©º token
                final_response += text  # ç´¯ç§¯å®Œæ•´çš„å“åº”
                payload = {
                    "type": "response_token",
                    "text": text,
                    "done": False,
                    "conversation_id": self.conversation_id,
                }

            # --- 2) Tool å¼€å§‹ / å‚æ•°å¢é‡ / ç»“æŸ ---
            elif kind == "on_tool_start":
                payload = {
                    "type": "tool_call_start",
                    "id": ev["data"].get("id"),
                    "name": str(ev["data"].get("name", "")),
                    "done": False,
                    "conversation_id": self.conversation_id,
                }
            elif kind == "on_tool_stream":
                payload = {
                    "type": "tool_call_chunk",
                    "id": ev["data"].get("id"),
                    "index": ev["data"]["index"],
                    "args_delta": str(ev["data"]["chunk"]),   # è½¬æˆå­—ç¬¦ä¸²
                    "done": False,
                    "conversation_id": self.conversation_id,
                }
            elif kind == "on_tool_end":
                payload = {
                    "type": "tool_output",
                    "id": ev["data"].get("id"),
                    "text": str(ev["data"]["output"]),        # ä¿è¯å¯ JSON
                    "done": False,
                    "conversation_id": self.conversation_id,
                }

            # --- 3) è‡ªå®šä¹‰ writer() ---
            elif kind == "on_custom_stream":
                payload = {
                    "type": "tool_progress",
                    "data": ev["data"],                      # writer() ä¿è¯æ•°æ®å¯ JSON
                    "conversation_id": self.conversation_id,
                }

            else:
                continue  # skip unhandled kinds

            # ---- send as plain JSON line ----
            yield json.dumps(payload) + "\n"

        # -------- final end --------
        yield json.dumps({
            "type": "end",
            "text": "",
            "done": True,
            "conversation_id": self.conversation_id,
        }) + "\n"

        # ä¿å­˜å¯¹è¯åˆ°æ•°æ®åº“
        if self.conversation_id and final_response:
            try:
                # è·å–å½“å‰ä¼šè¯çš„æ¶ˆæ¯
                _, existing_messages, image_urls, _, _ = load_conversation(self.conversation_id)
                
                # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯ï¼ˆå¦‚æœè¿˜æ²¡æœ‰æ·»åŠ ï¼‰
                if messages and messages[-1].role == "user":
                    existing_messages.append(messages[-1])
                
                # æ·»åŠ åŠ©æ‰‹å“åº”
                new_message = MessageInfo(
                    role="assistant",
                    content=final_response
                )
                existing_messages.append(new_message)
                
                # ä¿å­˜æ›´æ–°åçš„ä¼šè¯ä¿¡æ¯
                save_conversation(
                    conversation_id=self.conversation_id,
                    patient_info=self.patient_info,
                    input_items=existing_messages,
                    user_id=self.user_id,
                    image_urls=image_urls
                )
                logger.info(f"å¯¹è¯å·²ä¿å­˜åˆ°æ•°æ®åº“ï¼Œä¼šè¯ID: {self.conversation_id}, ç”¨æˆ·ID: {self.user_id}")
            except Exception as db_err:
                logger.error(f"ä¿å­˜å¯¹è¯åˆ°æ•°æ®åº“æ—¶å‡ºé”™: {str(db_err)}")


# =============================
# å…¨å±€æ–¹æ³•ï¼šlangchain_nurse_agent
# =============================

def nurse_agent_instance(cid: str) -> "NurseAgentGraph":
    if cid not in nurse_agent_graphs:
        nurse_agent_graphs[cid] = NurseAgentGraph(cid)
    return nurse_agent_graphs[cid]

nurse_agent_graphs: Dict[str, NurseAgentGraph] = {}


async def langchain_nurse_agent(messages: List[MessageInfo], conversation_id: str, user_id: str = "default_user") -> AsyncGenerator[str, None]:
    if not conversation_id:
        raise ValueError("æœªæä¾› conversation_id")
    agent_graph = nurse_agent_instance(conversation_id)
    async for chunk in agent_graph.process_message(messages, user_id):
        yield chunk
