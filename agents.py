import asyncio
import re
import uuid
import logging
import time
import os
from langchain.agents import AgentExecutor, create_openai_tools_agent  # Use openai_tools agent
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_core.tools import Tool, StructuredTool
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from patient_info import UserInfo, update_seat, normalize_gender  # Import UserInfo
from report_service import generate_medical_record  # Import if report tool is added
from typing import List, Tuple, Optional, Dict, Any, AsyncGenerator
from models import MessageInfo  # Use MessageInfo for consistency
from config import settings  # Import settings if needed for LLM config
from pydantic import BaseModel, Field
import json
from langchain.callbacks.streaming_aiter import AsyncIteratorCallbackHandler
from dataclasses import replace
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import START, MessagesState, StateGraph
from db import save_conversation, load_conversation  # ä¿®æ”¹ä¸ºæ­£ç¡®çš„å‡½æ•°å
from langgraph.config import get_stream_writer  # <- æ–°å¢ï¼šç”¨äºå·¥å…·å†…éƒ¨æµå¼å†™å…¥
from langchain.memory import ConversationBufferMemory

logger = logging.getLogger(__name__)
logger.setLevel(logging.WARNING)  # è®¾ç½®é»˜è®¤æ—¥å¿—çº§åˆ«ä¸ºWARNING


# -----------------------------
# æ•°æ®æ¨¡å‹å®šä¹‰ï¼ˆä¿æŒä¸å˜ï¼‰
# -----------------------------

class UpdatePatientInfoInput(BaseModel):
    """æ›´æ–°æ‚£è€…ä¿¡æ¯çš„è¾“å…¥æ¨¡å‹"""
    # åŸºæœ¬ä¿¡æ¯
    name: Optional[str] = Field(None, description="æ‚£è€…å§“å", examples=["å¼ ä¸‰"])
    age: Optional[int] = Field(None, description="æ‚£è€…å¹´é¾„", examples=[25])
    gender: Optional[str] = Field(None, description="æ‚£è€…æ€§åˆ«", examples=["ç”·", "å¥³"])
    occupation: Optional[str] = Field(None, description="èŒä¸š", examples=["æ•™å¸ˆ", "å·¥ç¨‹å¸ˆ"])
    phone: Optional[str] = Field(None, description="è”ç³»ç”µè¯", examples=["13800138000"])
    address: Optional[str] = Field(None, description="ä½å€", examples=["åŒ—äº¬å¸‚æµ·æ·€åŒºä¸­å…³æ‘å¤§è¡—1å·"])

    # å°±è¯Šä¿¡æ¯
    department: Optional[str] = Field(None, description="å°±è¯Šç§‘å®¤", examples=["å†…ç§‘", "å¤–ç§‘"])
    visit_time: Optional[str] = Field(None, description="å°±è¯Šæ—¶é—´", examples=["2024-03-20 14:30"])
    chief_complaint: Optional[str] = Field(None, description="ä¸»è¯‰", examples=["å‘çƒ­3å¤©ï¼Œå’³å—½2å¤©"])

    # ç—‡çŠ¶å’Œç—…å²
    symptoms: Optional[List[str]] = Field(None, description="ç—‡çŠ¶åˆ—è¡¨", examples=[["å‘çƒ­", "å’³å—½", "å¤´ç—›"]])
    medical_history: Optional[str] = Field(None, description="æ—¢å¾€ç—…å²", examples=["é«˜è¡€å‹ç—…å²5å¹´"])
    last_diagnosis: Optional[str] = Field(None, description="æœ€åè¯Šæ–­", examples=["ä¸Šå‘¼å¸é“æ„ŸæŸ“"])
    current_illness: Optional[str] = Field(None, description="ç°ç—…å²", examples=["3å¤©å‰å¼€å§‹å‘çƒ­ï¼Œæœ€é«˜ä½“æ¸©38.5â„ƒ"])
    family_history: Optional[str] = Field(None, description="å®¶æ—å²", examples=["çˆ¶äº²æœ‰é«˜è¡€å‹ç—…å²"])
    allergy_history: Optional[str] = Field(None, description="è¿‡æ•å²", examples=["å¯¹é’éœ‰ç´ è¿‡æ•"])
    personal_history: Optional[str] = Field(None, description="ä¸ªäººå²", examples=["æ— ç‰¹æ®Š"])

    # ä½“æ ¼æ£€æŸ¥
    physical_exam: Optional[str] = Field(None, description="ä½“æ ¼æ£€æŸ¥", examples=["ä½“æ¸©38.2â„ƒï¼Œå’½éƒ¨å……è¡€"])
    auxiliary_exam: Optional[str] = Field(None, description="è¾…åŠ©æ£€æŸ¥", examples=["è¡€å¸¸è§„ï¼šç™½ç»†èƒ12.5Ã—10^9/L"])
    treatment_plan: Optional[str] = Field(None, description="æ²»ç–—è®¡åˆ’", examples=["å£æœå¸ƒæ´›èŠ¬é€€çƒ­ï¼Œå¤šé¥®æ°´"])

    # ç”Ÿæ´»ä¹ æƒ¯
    smoking_history: Optional[Dict[str, str]] = Field(
        None, 
        description="å¸çƒŸå²ï¼ŒåŒ…å«status(çŠ¶æ€)ã€amount(é‡)ã€years(å¹´é™)",
        examples=[{"status": "å·²æˆ’çƒŸ", "amount": "20æ”¯/å¤©", "years": "10å¹´"}]
    )
    alcohol_history: Optional[Dict[str, str]] = Field(
        None, 
        description="é¥®é…’å²ï¼ŒåŒ…å«status(çŠ¶æ€)ã€frequency(é¢‘ç‡)ã€type(ç±»å‹)",
        examples=[{"status": "å¶å°”", "frequency": "æ¯å‘¨1-2æ¬¡", "type": "å•¤é…’"}]
    )

    # å¥³æ€§ç‰¹æœ‰ä¿¡æ¯
    menstrual_history: Optional[Dict[str, str]] = Field(
        None, 
        description="æœˆç»å²ï¼ŒåŒ…å«menarche_age(åˆæ½®å¹´é¾„)ã€last_menstrual_age(æœ«æ¬¡æœˆç»å¹´é¾„)ç­‰",
        examples=[{"menarche_age": "13å²", "last_menstrual_age": "28å¤©å‰"}]
    )

    # ç”Ÿè‚²å²
    fertility_history: Optional[Dict[str, str]] = Field(
        None, 
        description="ç”Ÿè‚²å²ï¼ŒåŒ…å«pregnancy_times(å¦Šå¨ æ¬¡æ•°)ã€delivery_times(åˆ†å¨©æ¬¡æ•°)ç­‰",
        examples=[{"pregnancy_times": "2æ¬¡", "delivery_times": "1æ¬¡"}]
    )

    # å©šå§»å²
    marriage_history: Optional[Dict[str, str]] = Field(
        None, 
        description="å©šå§»å²ï¼ŒåŒ…å«status(çŠ¶æ€)ã€marriage_age(ç»“å©šå¹´é¾„)ã€spouse_health(é…å¶å¥åº·çŠ¶å†µ)",
        examples=[{"status": "å·²å©š", "marriage_age": "25å²", "spouse_health": "å¥åº·"}]
    )

    # ä½“æ ¼æ•°æ®
    physical_data: Optional[Dict[str, str]] = Field(
        None, 
        description="ä½“æ ¼æ•°æ®ï¼ŒåŒ…å«temperature(ä½“æ¸©)ã€respiration(å‘¼å¸)ç­‰",
        examples=[{"temperature": "37.2â„ƒ", "respiration": "20æ¬¡/åˆ†", "pulse": "80æ¬¡/åˆ†", "blood_pressure": "120/80mmHg"}]
    )


class GenerateMedicalRecordInput(BaseModel):
    """ç”Ÿæˆç—…å†çš„è¾“å…¥æ¨¡å‹"""
    text: Optional[str] = Field(None, description="å¯é€‰çš„æ–‡æœ¬è¾“å…¥ï¼Œç”¨äºç”Ÿæˆç—…å†")


# -----------------------------
# LLM åˆå§‹åŒ–
# -----------------------------
try:
    llm = ChatOpenAI(
        api_key=settings.dashscope_api_key,
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        model=settings.dashscope_model,
        temperature=0.7
    )
    logger.debug(f"å·²åˆå§‹åŒ– LLM: {settings.dashscope_model} é€šè¿‡ ChatOpenAI æŒ‡å‘ DashScope ç«¯ç‚¹ã€‚")
except Exception as e:
    logger.critical(f"LLM åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
    raise RuntimeError(f"LLM åˆå§‹åŒ–å¤±è´¥: {e}")


# -----------------------------
# å ä½çš„æ‚£è€…ä¿¡æ¯æŠ½å–å™¨ï¼ˆä¿æŒä¸å˜ï¼‰
# -----------------------------
async def langchain_patient_info_extractor(patient_info: UserInfo, messages: List[MessageInfo]) -> UserInfo:
    logger.debug(f"ä¸ºæ‚£è€…è¿è¡Œä¿¡æ¯æå–å™¨: {patient_info.name}")
    full_text = "\n".join([f"{m.role}: {m.content}" for m in messages])
    age_match = re.search(r"æˆ‘ä»Šå¹´(\d+)\s*å²", full_text)
    if age_match and not patient_info.age:
        try:
            extracted_age = int(age_match.group(1))
            if 0 < extracted_age < 120:
                patient_info.age = extracted_age
                logger.debug(f"æå–å™¨æ›´æ–°æ‚£è€…å¹´é¾„ä¸º: {patient_info.age}")
        except (ValueError, IndexError):
            pass

    if patient_info.gender:
        patient_info.gender = normalize_gender(patient_info.gender)

    return patient_info


patient_info_store: Dict[str, UserInfo] = {}


# =============================
# NurseAgentGraph
# =============================
class NurseAgentGraph:
    def __init__(self, conversation_id: str = None):
        self.callback = AsyncIteratorCallbackHandler()
        self.conversation_id = conversation_id
        self.user_id = "default_user"  # é»˜è®¤ç”¨æˆ·ID

        # åˆå§‹åŒ–å¯¹è¯è®°å¿†
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True,
            output_key="output"
        )

        # åŠ è½½æ‚£è€…ä¿¡æ¯
        try:
            if conversation_id:
                patient_info, messages, image_urls, _, _ = load_conversation(conversation_id)
                self.patient_info = patient_info if patient_info else UserInfo()
                # åŠ è½½å†å²æ¶ˆæ¯åˆ°è®°å¿†
                for msg in messages:
                    if msg.role == "user":
                        self.memory.chat_memory.add_user_message(msg.content)
                    else:
                        self.memory.chat_memory.add_ai_message(msg.content)
            else:
                self.patient_info = UserInfo()
        except Exception:
            self.patient_info = UserInfo()

        # åˆå§‹åŒ–æµå¼ LLM
        self.model = ChatOpenAI(
            api_key=settings.dashscope_api_key,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            model=settings.dashscope_model,
            temperature=0.7,
            streaming=True,
            callbacks=[self.callback]
        )

        # LangGraph workflow
        self.workflow = StateGraph(state_schema=MessagesState)
        self.workflow.add_node("model", self.call_model)
        self.workflow.add_edge(START, "model")
        self.memory_saver = MemorySaver()
        if conversation_id:
            self.app = self.workflow.compile(checkpointer=self.memory_saver, name=f"nurse_agent_{conversation_id}")
        else:
            self.app = self.workflow.compile(checkpointer=self.memory_saver)

        logger.debug(f"NurseAgentGraph åˆå§‹åŒ–å®Œæˆï¼Œconversation_id: {conversation_id}")

    # -------------------------
    # å·¥å…·å®šä¹‰
    # -------------------------
    async def generate_medical_record_tool(self, text: Optional[str] = None) -> str:
        """ç”Ÿæˆç—…å†è®°å½•ï¼ˆæ”¯æŒæµå¼è¿›åº¦ï¼‰"""
        try:
            writer = get_stream_writer()  # ç”¨äºå®æ—¶è¿›åº¦
            writer({"stage": "start", "msg": "ğŸƒ æ­£åœ¨ç”Ÿæˆç—…å†â€¦â€¦"})
            result = await generate_medical_record(self.patient_info)
            if result:
                # ä¿å­˜ç—…å†åˆ°æ•°æ®åº“
                try:
                    # æ›´æ–°ä¼šè¯ä¸­çš„æ‚£è€…ä¿¡æ¯
                    if self.conversation_id:
                        # è·å–å½“å‰ä¼šè¯çš„æ¶ˆæ¯
                        _, messages, image_urls, _, _ = load_conversation(self.conversation_id)
                        # ä¿å­˜æ›´æ–°åçš„ä¼šè¯ä¿¡æ¯
                        save_conversation(
                            conversation_id=self.conversation_id,
                            patient_info=self.patient_info,
                            input_items=messages,
                            user_id=self.user_id,
                            image_urls=[result]
                        )
                        logger.info(f"ç—…å†å·²ä¿å­˜åˆ°æ•°æ®åº“ï¼Œä¼šè¯ID: {self.conversation_id}, ç”¨æˆ·ID: {self.user_id}")
                except Exception as db_err:
                    logger.error(f"ä¿å­˜ç—…å†åˆ°æ•°æ®åº“æ—¶å‡ºé”™: {str(db_err)}")
                    return f"ç”Ÿæˆç—…å†æˆåŠŸï¼Œä½†ä¿å­˜åˆ°æ•°æ®åº“æ—¶å‡ºé”™ï¼š{str(db_err)}"

                output = f"å·²æˆåŠŸç”Ÿæˆç—…å†ï¼Œè¯·ç‚¹å‡»é“¾æ¥æŸ¥çœ‹ï¼š{result}"
                writer({"stage": "done"})
                return output
            else:
                return "ç”Ÿæˆç—…å†å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
        except Exception as e:
            return f"ç”Ÿæˆç—…å†æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"

    async def update_patient_info_tool(self, **kwargs) -> str:
        """æ›´æ–°æ‚£è€…ä¿¡æ¯"""
        try:
            # 1. å‚æ•°éªŒè¯å’Œè½¬æ¢
            update_info = {k: v for k, v in kwargs.items() if v is not None}
            if not update_info:
                return "æ²¡æœ‰æä¾›ä»»ä½•éœ€è¦æ›´æ–°çš„ä¿¡æ¯"

            # éªŒè¯è¾“å…¥æ•°æ®
            validation_errors = []
            for key, value in update_info.items():
                if key == "age" and not isinstance(value, int):
                    validation_errors.append(f"å¹´é¾„å¿…é¡»æ˜¯æ•´æ•°ï¼Œå½“å‰å€¼: {value}")
                elif key == "symptoms" and not isinstance(value, list):
                    validation_errors.append(f"ç—‡çŠ¶å¿…é¡»æ˜¯åˆ—è¡¨ï¼Œå½“å‰å€¼: {value}")
                elif key in ["smoking_history", "alcohol_history", "menstrual_history", 
                           "fertility_history", "marriage_history", "physical_data"]:
                    if not isinstance(value, dict):
                        validation_errors.append(f"{key}å¿…é¡»æ˜¯å­—å…¸ç±»å‹ï¼Œå½“å‰å€¼: {value}")

            if validation_errors:
                return "è¾“å…¥æ•°æ®éªŒè¯å¤±è´¥ï¼š\n" + "\n".join(validation_errors)

            # 2. åˆ›å»ºæ‚£è€…ä¿¡æ¯å‰¯æœ¬å¹¶æ›´æ–°
            try:
                updated_info = replace(self.patient_info)
                for key, value in update_info.items():
                    if hasattr(updated_info, key):
                        setattr(updated_info, key, value)
                    else:
                        logger.warning(f"å°è¯•æ›´æ–°ä¸å­˜åœ¨çš„å­—æ®µ: {key}")
                self.patient_info = updated_info
            except Exception as e:
                logger.error(f"æ›´æ–°æ‚£è€…ä¿¡æ¯å¯¹è±¡æ—¶å‡ºé”™: {str(e)}")
                return f"æ›´æ–°æ‚£è€…ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}"

            # 3. ä¿å­˜åˆ°æ•°æ®åº“
            try:
                if self.conversation_id:
                    # è·å–å½“å‰ä¼šè¯çš„æ¶ˆæ¯
                    _, messages, image_urls, _, _ = load_conversation(self.conversation_id)
                    # ä¿å­˜æ›´æ–°åçš„ä¼šè¯ä¿¡æ¯
                    success = save_conversation(
                        conversation_id=self.conversation_id,
                        patient_info=self.patient_info,
                        input_items=messages,
                        user_id=self.user_id,
                        image_urls=image_urls
                    )
                    if not success:
                        logger.error("ä¿å­˜æ‚£è€…ä¿¡æ¯åˆ°æ•°æ®åº“å¤±è´¥")
                        return "æ›´æ–°æ‚£è€…ä¿¡æ¯æˆåŠŸï¼Œä½†ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥"
                    logger.info(f"æ‚£è€…ä¿¡æ¯å·²æ›´æ–°åˆ°æ•°æ®åº“ï¼Œä¼šè¯ID: {self.conversation_id}, ç”¨æˆ·ID: {self.user_id}")
            except Exception as db_err:
                logger.error(f"æ›´æ–°æ‚£è€…ä¿¡æ¯åˆ°æ•°æ®åº“æ—¶å‡ºé”™: {str(db_err)}")
                return f"æ›´æ–°æ‚£è€…ä¿¡æ¯æˆåŠŸï¼Œä½†ä¿å­˜åˆ°æ•°æ®åº“æ—¶å‡ºé”™ï¼š{str(db_err)}"

            # 4. è¿”å›æ›´æ–°ä¿¡æ¯
            output = "æ‚£è€…ä¿¡æ¯å·²æ›´æ–°ï¼š" + ", ".join(f"{k}={v}" for k, v in update_info.items())
            return output
        except Exception as e:
            logger.error(f"æ›´æ–°æ‚£è€…ä¿¡æ¯æ—¶å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {str(e)}", exc_info=True)
            return f"æ›´æ–°æ‚£è€…ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

    # -------------------------
    # LangGraph èŠ‚ç‚¹ï¼šè°ƒç”¨æ¨¡å‹
    # -------------------------
    async def call_model(self, state: MessagesState) -> Dict[str, Any]:
        tools = [
            StructuredTool(
                name="generate_medical_record",
                func=self.generate_medical_record_tool,
                description="ç”Ÿæˆæ‚£è€…çš„ç—…å†è®°å½•ã€‚",
                args_schema=GenerateMedicalRecordInput,
                coroutine=self.generate_medical_record_tool,
                async_callable=True,
            ),
            StructuredTool(
                name="update_patient_info",
                func=self.update_patient_info_tool,
                description="""æ›´æ–°æ‚£è€…ä¿¡æ¯ã€‚æ­¤å·¥å…·ç”¨äºè®°å½•å’Œæ›´æ–°æ‚£è€…çš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
1. åŸºæœ¬ä¿¡æ¯ï¼ˆå§“åã€å¹´é¾„ã€æ€§åˆ«ç­‰ï¼‰
2. å°±è¯Šä¿¡æ¯ï¼ˆç§‘å®¤ã€æ—¶é—´ã€ä¸»è¯‰ç­‰ï¼‰
3. ç—‡çŠ¶å’Œç—…å²ï¼ˆç—‡çŠ¶åˆ—è¡¨ã€æ—¢å¾€ç—…å²ç­‰ï¼‰
4. ä½“æ ¼æ£€æŸ¥ï¼ˆæ£€æŸ¥ç»“æœã€è¾…åŠ©æ£€æŸ¥ç­‰ï¼‰
5. ç”Ÿæ´»ä¹ æƒ¯ï¼ˆå¸çƒŸå²ã€é¥®é…’å²ç­‰ï¼‰
6. å¥³æ€§ç‰¹æœ‰ä¿¡æ¯ï¼ˆæœˆç»å²ç­‰ï¼‰
7. ç”Ÿè‚²å²å’Œå©šå§»å²
8. ä½“æ ¼æ•°æ®ï¼ˆä½“æ¸©ã€å‘¼å¸ç­‰ï¼‰

æ‰€æœ‰å­—æ®µéƒ½æ˜¯å¯é€‰çš„ï¼Œåªéœ€è¦æä¾›éœ€è¦æ›´æ–°çš„ä¿¡æ¯å³å¯ã€‚""",
                args_schema=UpdatePatientInfoInput,
                coroutine=self.update_patient_info_tool,
                async_callable=True,
            ),
        ]

        system_prompt_template = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIæŠ¤å£«åŠ©æ‰‹ã€‚ä½ çš„ä¸»è¦èŒè´£æ˜¯å®æ—¶æ›´æ–°å’Œè®°å½•æ‚£è€…ä¿¡æ¯ã€‚

é‡è¦æç¤ºï¼š
1. æ¯å½“æ‚£è€…æä¾›ä»»ä½•æ–°çš„ä¿¡æ¯æ—¶ï¼Œå¿…é¡»ç«‹å³è°ƒç”¨ update_patient_info å·¥å…·è¿›è¡Œæ›´æ–°
2. æ›´æ–°æ‚£è€…ä¿¡æ¯æ˜¯æœ€é«˜ä¼˜å…ˆçº§çš„ä»»åŠ¡ï¼Œå¿…é¡»åœ¨å…¶ä»–æ“ä½œä¹‹å‰å®Œæˆ
3. å³ä½¿æ‚£è€…åªæä¾›äº†ä¸€æ¡ä¿¡æ¯ï¼Œä¹Ÿè¦ç«‹å³è°ƒç”¨ update_patient_info å·¥å…·æ›´æ–°
4. åªæœ‰æ‚£è€…æå‡ºç”Ÿæˆç—…å†æ—¶ï¼Œå†è°ƒç”¨ generate_medical_record å·¥å…·
5. å¦‚æœå‘ç°æ‚£è€…ä¿¡æ¯æœ‰ä»»ä½•å˜åŒ–ï¼Œå¿…é¡»ç«‹å³è°ƒç”¨ update_patient_info å·¥å…·æ›´æ–°

ä¸»åŠ¨é‡‡é›†ä¿¡æ¯æŒ‡å—ï¼š
1. é¦–æ¬¡å¯¹è¯æ—¶ï¼Œä¸»åŠ¨è¯¢é—®æ‚£è€…çš„åŸºæœ¬ä¿¡æ¯ï¼ˆå§“åã€å¹´é¾„ã€æ€§åˆ«ç­‰ï¼‰
2. æ ¹æ®æ‚£è€…çš„ä¸»è¯‰ï¼Œä¸»åŠ¨è¯¢é—®ç›¸å…³çš„ç—‡çŠ¶å’Œç—…å²
3. å¯¹äºå¥³æ€§æ‚£è€…ï¼Œé€‚æ—¶è¯¢é—®æœˆç»å²å’Œç”Ÿè‚²å²
4. è¯¢é—®æ‚£è€…çš„ç”Ÿæ´»ä¹ æƒ¯ï¼ˆå¸çƒŸã€é¥®é…’ç­‰ï¼‰
5. è¯¢é—®å®¶æ—å²å’Œè¿‡æ•å²
6. è®°å½•ä½“æ ¼æ£€æŸ¥ç»“æœå’Œè¾…åŠ©æ£€æŸ¥ç»“æœ
7. æ ¹æ®ç—…æƒ…éœ€è¦ï¼Œä¸»åŠ¨è¯¢é—®å…¶ä»–ç›¸å…³ä¿¡æ¯

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸Šè§„åˆ™æ“ä½œï¼Œç¡®ä¿æ‚£è€…ä¿¡æ¯çš„å®æ—¶æ€§å’Œå‡†ç¡®æ€§ã€‚"""),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])

        agent = create_openai_tools_agent(self.model, tools, system_prompt_template)
        agent_executor = AgentExecutor(
            agent=agent,
            tools=tools,
            memory=self.memory,
            verbose=True,
        )

        # ç”¨ agent_executor ç›´æ¥è¿”å› AIMessageï¼Œäº¤ç»™ LangGraph
        result = await agent_executor.ainvoke({
            "input": state["messages"][-1].content,
            "chat_history": state["messages"][:-1],
            "agent_scratchpad": [],
        })
        if isinstance(result, dict) and "output" in result:
            state["messages"].append(AIMessage(content=result["output"]))
        return {"messages": state["messages"]}

    # -------------------------
    # å¯¹å¤–å…¥å£ï¼šæµå¼å¤„ç†æ¶ˆæ¯
    # -------------------------
    async def process_message(self, messages: List[MessageInfo], user_id: str):
        """è¾¹ç”Ÿæˆè¾¹ yield SSE è¡Œï¼štokenã€å·¥å…·è¿›åº¦ã€æœ€ç»ˆç»“æœ"""
        # æ›´æ–°ç”¨æˆ·ID
        self.user_id = user_id

        # -------- Build LC messages --------
        lc_msgs = [
            HumanMessage(content=m.content) if m.role == "user"
            else AIMessage(content=m.content)
            for m in messages
        ]

        # -------- Build AgentExecutor --------
        tools = [
            StructuredTool(
                name="generate_medical_record",
                func=self.generate_medical_record_tool,
                description="""ç”Ÿæˆæ‚£è€…çš„ç—…å†è®°å½•ã€‚æ­¤å·¥å…·ä¼šä½¿ç”¨å½“å‰ä¼šè¯ä¸­æ”¶é›†åˆ°çš„æ‰€æœ‰æ‚£è€…ä¿¡æ¯ã€‚""",
                args_schema=GenerateMedicalRecordInput,
                coroutine=self.generate_medical_record_tool,
                async_callable=True,
            ),
            StructuredTool(
                name="update_patient_info",
                func=self.update_patient_info_tool,
                description="""æ›´æ–°æ‚£è€…ä¿¡æ¯ã€‚æ­¤å·¥å…·ç”¨äºè®°å½•å’Œæ›´æ–°æ‚£è€…çš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
1. åŸºæœ¬ä¿¡æ¯ï¼ˆå§“åã€å¹´é¾„ã€æ€§åˆ«ç­‰ï¼‰
2. å°±è¯Šä¿¡æ¯ï¼ˆç§‘å®¤ã€æ—¶é—´ã€ä¸»è¯‰ç­‰ï¼‰
3. ç—‡çŠ¶å’Œç—…å²ï¼ˆç—‡çŠ¶åˆ—è¡¨ã€æ—¢å¾€ç—…å²ç­‰ï¼‰
4. ä½“æ ¼æ£€æŸ¥ï¼ˆæ£€æŸ¥ç»“æœã€è¾…åŠ©æ£€æŸ¥ç­‰ï¼‰
5. ç”Ÿæ´»ä¹ æƒ¯ï¼ˆå¸çƒŸå²ã€é¥®é…’å²ç­‰ï¼‰
6. å¥³æ€§ç‰¹æœ‰ä¿¡æ¯ï¼ˆæœˆç»å²ç­‰ï¼‰
7. ç”Ÿè‚²å²å’Œå©šå§»å²
8. ä½“æ ¼æ•°æ®ï¼ˆä½“æ¸©ã€å‘¼å¸ç­‰ï¼‰

æ‰€æœ‰å­—æ®µéƒ½æ˜¯å¯é€‰çš„ï¼Œåªéœ€è¦æä¾›éœ€è¦æ›´æ–°çš„ä¿¡æ¯å³å¯ã€‚""",
                args_schema=UpdatePatientInfoInput,
                coroutine=self.update_patient_info_tool,
                async_callable=True,
            ),
        ]
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIæŠ¤å£«åŠ©æ‰‹ã€‚ä½ çš„ä¸»è¦èŒè´£æ˜¯å®æ—¶æ›´æ–°å’Œè®°å½•æ‚£è€…ä¿¡æ¯ã€‚

é‡è¦æç¤ºï¼š
1. æ¯å½“æ‚£è€…æä¾›ä»»ä½•æ–°çš„ä¿¡æ¯æ—¶ï¼Œå¿…é¡»ç«‹å³è°ƒç”¨ update_patient_info å·¥å…·è¿›è¡Œæ›´æ–°
2. æ›´æ–°æ‚£è€…ä¿¡æ¯æ˜¯æœ€é«˜ä¼˜å…ˆçº§çš„ä»»åŠ¡ï¼Œå¿…é¡»åœ¨å…¶ä»–æ“ä½œä¹‹å‰å®Œæˆ
3. å³ä½¿æ‚£è€…åªæä¾›äº†ä¸€æ¡ä¿¡æ¯ï¼Œä¹Ÿè¦ç«‹å³è°ƒç”¨ update_patient_info å·¥å…·æ›´æ–°
4. åªæœ‰æ‚£è€…æå‡ºç”Ÿæˆç—…å†æ—¶ï¼Œå†è°ƒç”¨ generate_medical_record å·¥å…·
5. å¦‚æœå‘ç°æ‚£è€…ä¿¡æ¯æœ‰ä»»ä½•å˜åŒ–ï¼Œå¿…é¡»ç«‹å³è°ƒç”¨ update_patient_info å·¥å…·æ›´æ–°

ä¸»åŠ¨é‡‡é›†ä¿¡æ¯æŒ‡å—ï¼š
1. é¦–æ¬¡å¯¹è¯æ—¶ï¼Œä¸»åŠ¨è¯¢é—®æ‚£è€…çš„åŸºæœ¬ä¿¡æ¯ï¼ˆå§“åã€å¹´é¾„ã€æ€§åˆ«ç­‰ï¼‰
2. æ ¹æ®æ‚£è€…çš„ä¸»è¯‰ï¼Œä¸»åŠ¨è¯¢é—®ç›¸å…³çš„ç—‡çŠ¶å’Œç—…å²
3. å¯¹äºå¥³æ€§æ‚£è€…ï¼Œé€‚æ—¶è¯¢é—®æœˆç»å²å’Œç”Ÿè‚²å²
4. è¯¢é—®æ‚£è€…çš„ç”Ÿæ´»ä¹ æƒ¯ï¼ˆå¸çƒŸã€é¥®é…’ç­‰ï¼‰
5. è¯¢é—®å®¶æ—å²å’Œè¿‡æ•å²
6. è®°å½•ä½“æ ¼æ£€æŸ¥ç»“æœå’Œè¾…åŠ©æ£€æŸ¥ç»“æœ
7. æ ¹æ®ç—…æƒ…éœ€è¦ï¼Œä¸»åŠ¨è¯¢é—®å…¶ä»–ç›¸å…³ä¿¡æ¯

å†å²ä¿¡æ¯ä½¿ç”¨æŒ‡å—ï¼š
1. ä»”ç»†é˜…è¯»å†å²å¯¹è¯ï¼Œäº†è§£å·²ç»æ”¶é›†åˆ°çš„æ‚£è€…ä¿¡æ¯
2. é¿å…é‡å¤è¯¢é—®å·²ç»æä¾›è¿‡çš„ä¿¡æ¯
3. æ ¹æ®å·²æœ‰ä¿¡æ¯ï¼Œæœ‰é’ˆå¯¹æ€§åœ°è¯¢é—®ç¼ºå¤±çš„ä¿¡æ¯
4. å¦‚æœå‘ç°å†å²ä¿¡æ¯æœ‰æ›´æ–°ï¼ŒåŠæ—¶è°ƒç”¨ update_patient_info å·¥å…·æ›´æ–°

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸Šè§„åˆ™æ“ä½œï¼Œç¡®ä¿æ‚£è€…ä¿¡æ¯çš„å®æ—¶æ€§å’Œå‡†ç¡®æ€§ã€‚"""),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])
        agent = create_openai_tools_agent(self.model, tools, prompt)
        agent_exec = AgentExecutor(
            agent=agent,
            tools=tools,
            memory=self.memory,
            verbose=True
        )

        # -------- Stream events --------
        final_response = ""
        async for ev in agent_exec.astream_events(
            {
                "input": lc_msgs[-1].content  # âœ… ä»…æ­¤é¡¹ï¼Œmemory ä¼šè‡ªåŠ¨æ³¨å…¥å†å²
            },
            version="v1",
        ):
            kind = ev["event"]
            payload: dict

            # --- 1) LLM tokenï¼ˆè‹¥æ¨¡å‹æ”¯æŒæµå¼ï¼‰ ---
            if kind in ("on_chat_model_stream", "on_llm_stream"):
                chunk_obj = ev["data"]["chunk"]
                text = getattr(chunk_obj, "content", str(chunk_obj))
                if not text:
                    continue  # è·³è¿‡ç©º token
                final_response += text  # ç´¯ç§¯å®Œæ•´çš„å“åº”
                payload = {
                    "type": "response_token",
                    "text": text,
                    "done": False,
                    "conversation_id": self.conversation_id,
                }

            # --- 2) Tool å¼€å§‹ / å‚æ•°å¢é‡ / ç»“æŸ ---
            elif kind == "on_tool_start":
                payload = {
                    "type": "tool_call_start",
                    "id": ev["data"].get("id"),
                    "name": str(ev["data"].get("name", "")),
                    "done": False,
                    "conversation_id": self.conversation_id,
                }
            elif kind == "on_tool_stream":
                payload = {
                    "type": "tool_call_chunk",
                    "id": ev["data"].get("id"),
                    "index": ev["data"]["index"],
                    "args_delta": str(ev["data"]["chunk"]),   # è½¬æˆå­—ç¬¦ä¸²
                    "done": False,
                    "conversation_id": self.conversation_id,
                }
            elif kind == "on_tool_end":
                payload = {
                    "type": "tool_output",
                    "id": ev["data"].get("id"),
                    "text": str(ev["data"]["output"]),        # ä¿è¯å¯ JSON
                    "done": False,
                    "conversation_id": self.conversation_id,
                }

            # --- 3) è‡ªå®šä¹‰ writer() ---
            elif kind == "on_custom_stream":
                payload = {
                    "type": "tool_progress",
                    "data": ev["data"],                      # writer() ä¿è¯æ•°æ®å¯ JSON
                    "conversation_id": self.conversation_id,
                }

            else:
                continue  # skip unhandled kinds

            # ---- send as plain JSON line ----
            yield json.dumps(payload) + "\n"

        # -------- final end --------
        yield json.dumps({
            "type": "end",
            "text": "",
            "done": True,
            "conversation_id": self.conversation_id,
        }) + "\n"

        # ä¿å­˜å¯¹è¯åˆ°æ•°æ®åº“
        if self.conversation_id and final_response:
            try:
                # è·å–å½“å‰ä¼šè¯çš„æ¶ˆæ¯
                _, existing_messages, image_urls, _, _ = load_conversation(self.conversation_id)
                
                # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯ï¼ˆå¦‚æœè¿˜æ²¡æœ‰æ·»åŠ ï¼‰
                if messages and messages[-1].role == "user":
                    existing_messages.append(messages[-1])
                
                # æ·»åŠ åŠ©æ‰‹å“åº”
                new_message = MessageInfo(
                    role="assistant",
                    content=final_response
                )
                existing_messages.append(new_message)
                
                # ä¿å­˜æ›´æ–°åçš„ä¼šè¯ä¿¡æ¯
                save_conversation(
                    conversation_id=self.conversation_id,
                    patient_info=self.patient_info,
                    input_items=existing_messages,
                    user_id=self.user_id,
                    image_urls=image_urls
                )
                logger.info(f"å¯¹è¯å·²ä¿å­˜åˆ°æ•°æ®åº“ï¼Œä¼šè¯ID: {self.conversation_id}, ç”¨æˆ·ID: {self.user_id}")
            except Exception as db_err:
                logger.error(f"ä¿å­˜å¯¹è¯åˆ°æ•°æ®åº“æ—¶å‡ºé”™: {str(db_err)}")


# =============================
# å…¨å±€æ–¹æ³•ï¼šlangchain_nurse_agent
# =============================

def nurse_agent_instance(cid: str) -> "NurseAgentGraph":
    if cid not in nurse_agent_graphs:
        nurse_agent_graphs[cid] = NurseAgentGraph(cid)
    return nurse_agent_graphs[cid]

nurse_agent_graphs: Dict[str, NurseAgentGraph] = {}


async def langchain_nurse_agent(messages: List[MessageInfo], conversation_id: str, user_id: str = "default_user") -> AsyncGenerator[str, None]:
    if not conversation_id:
        raise ValueError("æœªæä¾› conversation_id")
    agent_graph = nurse_agent_instance(conversation_id)
    async for chunk in agent_graph.process_message(messages, user_id):
        yield chunk
